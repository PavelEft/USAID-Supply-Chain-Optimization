{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019, Pavel Eftimovski, All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section: Data Preprocessing ##\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "\n",
    "#SCMS Data:\n",
    "\n",
    "# generate blocks of columns from same data type, count rows with null values\n",
    "def sort_by_type(dataset):\n",
    "    \n",
    "    new_column_names = ['id', 'p_code',\n",
    "                        'pq', 'po_so',\n",
    "                        'asn_dn',\n",
    "                        'country',\n",
    "                        'managed_by',\n",
    "                        'flf_via',\n",
    "                        'vendor_terms',\n",
    "                        'ship_mode',\n",
    "                        'pq_client_date',\n",
    "                        'po_vendor_date',\n",
    "                        'sch_del_date',\n",
    "                        'del_date',\n",
    "                        'rec_del_date',\n",
    "                        'product_grp',\n",
    "                        'sub_class',\n",
    "                        'vendor',\n",
    "                        'itm_desc',\n",
    "                        'mol_test',\n",
    "                        'brand',\n",
    "                        'dosage',\n",
    "                        'dos_form',\n",
    "                        'unit_msr',\n",
    "                        'ln_itm_qty',\n",
    "                        'ln_itm_val',\n",
    "                        'pack_price',\n",
    "                        'unit_price',\n",
    "                        'manu_site',\n",
    "                        'first_line',\n",
    "                        'weight',\n",
    "                        'freight_cost',\n",
    "                        'line_item']\n",
    "    \n",
    "    dataset = pd.read_excel(dataset)\n",
    "    newcol_dict = dict(zip(dataset.columns, new_column_names))\n",
    "    dataset.rename(columns=(newcol_dict), inplace =True)\n",
    "    blocks = dataset.as_blocks()\n",
    "    \n",
    "    for key in blocks.keys():\n",
    "        print(\"Type: {} , Count: {} \\nColumn name and null counts: \\n{}\\n\".format(\n",
    "            key,len(blocks[key].columns),blocks[key].isnull().sum()))\n",
    "        \n",
    "    return blocks\n",
    "\n",
    "\n",
    "# replace null/nan values\n",
    "def replace_nan(data, column, fillvalue):\n",
    "    print(\"-Before: \\n\", data.isnull().sum()[data.isnull().sum()>0])\n",
    "    # use 'TestKit/Ancillary' as dosage value\n",
    "    data[column].fillna(value=fillvalue, inplace=True)\n",
    "    # re-check null values\n",
    "    print(\"\\n-After: \\n\", data.isnull().sum()[data.isnull().sum()>0])\n",
    "    return data\n",
    "\n",
    "\n",
    "# describes the columns with null/nan values\n",
    "def describe_nulls(data, column):\n",
    "    nulls = data[data[column].isnull()]\n",
    "    for col in nulls:\n",
    "        print('\\n-------\\n',nulls[col].describe())\n",
    "\n",
    "        \n",
    "# otuput a summary of columns that correspond to null column\n",
    "def nan_desc(data, column):\n",
    "    is_null = data[data[column].isnull()]\n",
    "    for col in is_null:\n",
    "        print('\\n-------\\n',is_null[col].describe())\n",
    "\n",
    "        \n",
    "# LPI Data: rank countries by score in missing years\n",
    "def rank_missing(df_countries, missing_col):\n",
    "    for row in missing_col:\n",
    "      year, suffix = row.split(':')[0], row.split(':')[1]\n",
    "      col_base = suffix.split('_')[0]\n",
    "      if '_rank' in row:\n",
    "         df_countries[row]=df_countries[year+':'+col_base+'_score'].rank(ascending=0)\n",
    "\n",
    "            \n",
    "# Locate manufacturing site with Google Maps API:\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "main_p = '.../USAID_Data/' \n",
    "ctry_cont = pd.read_csv(main_p+\"country code_to continent.csv\") # country location in continents\n",
    "ctry_cont_dict = {x:y for x,y in zip(ctry_cont['Country Code'],ctry_cont['Continent'])}\n",
    "    \n",
    "def locateSite(manu_site, ctry_cont_dict = ctry_cont_dict):\n",
    "    \n",
    "    google_api = \"https://maps.googleapis.com/maps/api/geocode/json?\"\n",
    "    API_KEY = '...' \n",
    "    url = google_api + urllib.parse.urlencode({'address': manu_site}) # set the location's url on the map    \n",
    "    \n",
    "    json = requests.get(url, params={\"key\": API_KEY}).json()# get data in .json format    \n",
    "    \n",
    "    f_address = json['results'][0]['formatted_address'] # extract formatted adress\n",
    "    items_bool = [x['types'] == ['country', 'political'] for x in json['results'][0]['address_components']]\n",
    "    i = items_bool.index(True)\n",
    "    ctry_code = json['results'][0]['address_components'][i]['short_name'] # get short name of country\n",
    "    ctry = json['results'][0]['address_components'][i]['long_name'] # get long name of country\n",
    "    cnt= ctry_cont_dict[ctry_code] #get continent\n",
    "    return f_address, ctry, cnt\n",
    "\n",
    "\n",
    "# compare contries from two data frames\n",
    "def compare_countries(df1,df2,ctry1,ctry2):\n",
    "    \n",
    "    fsi_ser, lpi_ser = pd.Series(df1[ctry1].unique(), name='fsi'),pd.Series(df2[ctry2].unique(), name='lpi')\n",
    "    print(\"df1 shape:\",len(fsi_ser),\"df2 shape:\",len(lpi_ser))\n",
    "    \n",
    "    comparison_df = pd.merge(pd.DataFrame(fsi_ser),pd.DataFrame(lpi_ser), left_on='fsi', right_on='lpi'\n",
    "             , suffixes=('_fsi', '_lsi'), how='outer')\n",
    "    \n",
    "    # output comparison\n",
    "    df1_not_df2 = list(comparison_df[comparison_df.fsi.isnull()].lpi)\n",
    "    df2_not_df1 = list(comparison_df[comparison_df.lpi.isnull()].fsi)\n",
    "    print(\"In df1, not in df2 length: {} \\nIn df2, not in df1 length: {}\".format(len(df1_not_df2), len(df2_not_df1)))\n",
    "    print(\"In df1, not in df2: {} \\nIn df2, not in df1: {}\".format(df1_not_df2, df2_not_df1))\n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "# split df to features\n",
    "def split_to_features(t_data, base_exam, feat_names):\n",
    "    features_dict = {}\n",
    "    temp = 0\n",
    "    for i in range(len(feat_names)):\n",
    "        if 'item_desc' in feat_names[i]: \n",
    "            features_dict[feat_names[i]] = t_data.iloc[:, :len(base_exam[i].columns)]\n",
    "        else:\n",
    "            features_dict[feat_names[i]] = t_data.iloc[:, \n",
    "            len(base_exam[i-1].columns)+temp:len(base_exam[i-1].columns)+len(base_exam[i].columns)+temp]\n",
    "            temp += len(base_exam[i-1].columns)\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section: Data Exploration ##\n",
    "\n",
    "# import model data\n",
    "def import_sel_data(files_path, feat_names):\n",
    "    \n",
    "    file_names = [feat_names[i]+\".csv\" for i in range(len(feat_names))]\n",
    "    file_dict = {f: None for f in feat_names}\n",
    "\n",
    "    for f in range(len(file_names)):\n",
    "        file_dict[feat_names[f]] = pd.read_csv(files_path + file_names[f])\n",
    "    \n",
    "    for file in file_dict.values():\n",
    "        try:\n",
    "            file.drop('Unnamed: 0', axis=1, inplace=True) # drop unnamed column\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return file_dict\n",
    "\n",
    "\n",
    "# one-hot-encoder\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "class OneHotEncoder(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cat=True):\n",
    "        self.cat = cat\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._validate = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self._validate = True\n",
    "        return pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    \n",
    "# labeler\n",
    "class LabelBiner(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, lab=True):\n",
    "        self.lab = lab\n",
    "    \n",
    "    def fit(self, y, X=None):\n",
    "        self._validate = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        self._validate = True\n",
    "        enc = LabelBinarizer()\n",
    "        return enc.fit_transform(y)\n",
    "\n",
    "    \n",
    "# output PCA results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def describe_pca(df, pca):\n",
    "\n",
    "    # components\n",
    "    dims = ['Component {}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
    "    comps = pd.DataFrame(np.round(pca.components_, 4), columns = df.keys())\n",
    "    comps.index = dims\n",
    "    \n",
    "    # variance\n",
    "    r = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\n",
    "    var = pd.DataFrame(np.round(r, 4), columns = ['Variance'])\n",
    "    var.index = dims\n",
    "    \n",
    "    # visualize\n",
    "    fig, ((ax0,ax1),(ax2,ax3)) = plt.subplots(\n",
    "        nrows=2, ncols=2, figsize=(14,10))\n",
    "    axes = [ax0,ax1,ax2,ax3]\n",
    "    \n",
    "    # plot\n",
    "    for dim in dims:\n",
    "        i = dims.index(dim)\n",
    "        idx = abs(comps.loc[dim,:])>0.1 # select features with > 10% contribution\n",
    "        comps.loc[dim,:][idx].sort_values(ascending=False).plot(\n",
    "                                                    kind=\"barh\",\n",
    "                                                    ax=axes[i],\n",
    "                                                    title=dim)\n",
    "        axes[i].set_xlabel(\"Feature Contribution\")\n",
    "\n",
    "    pd.concat([var, comps], axis = 1)\n",
    "\n",
    "    \n",
    "# fill nulls\n",
    "def fix_nulls(df):\n",
    "    df_nulls = df.isnull().sum()[df.isnull().sum()>0].index.tolist()\n",
    "    for c in df_nulls:\n",
    "        try:\n",
    "            cmean = df[c].mean()\n",
    "            df[c].fillna(cmean, inplace=True)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section: ML Model Building ##\n",
    "\n",
    "# categorical data pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def cat_pipeline(s_objects, s_ts_objects):\n",
    "    s_objects['train'] = 1\n",
    "    s_ts_objects['train'] = 0\n",
    "    temp_objects = pd.concat([s_objects, s_ts_objects])\n",
    "\n",
    "    one_hot_pipeline = make_pipeline(OneHotEncoder())\n",
    "    temp_objects = one_hot_pipeline.fit_transform(temp_objects)\n",
    "\n",
    "    s_objects = temp_objects.loc[temp_objects['train'] == 1]\n",
    "    s_ts_objects = temp_objects.loc[temp_objects['train'] == 0]\n",
    "    s_objects.drop(['train'], axis=1, inplace=True)\n",
    "    s_ts_objects.drop(['train'], axis=1, inplace=True)\n",
    "    \n",
    "    return s_objects, s_ts_objects\n",
    "\n",
    "\n",
    "# numerical data pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "def transform_pipepline(t_objects, s_num_log, si, sc, sv, sm, sb, sml, trending, del_del):\n",
    "\n",
    "    log_transform = FunctionTransformer(np.log1p)\n",
    "    log_stand_pipeline = make_pipeline(log_transform, StandardScaler()) \n",
    "    stand_pipeline = make_pipeline(StandardScaler()) \n",
    "    lab_pipeline = make_pipeline(LabelBiner())\n",
    "\n",
    "    ti, tc, tv, tm, tb, tml = [pd.DataFrame(log_stand_pipeline.fit_transform(d)\n",
    "                                            , index=d.index\n",
    "                                            , columns=d.columns) for d in [si, sc, sv, sm, sb, sml]]\n",
    "    \n",
    "    t_num_log = pd.DataFrame(stand_pipeline.fit_transform(s_num_log)\n",
    "                                             , index=s_num_log.index\n",
    "                                             , columns=s_num_log.columns)\n",
    "\n",
    "    tt = pd.DataFrame(stand_pipeline.fit_transform(trending)\n",
    "                                             , index=trending.index\n",
    "                                             , columns=trending.columns)\n",
    "    \n",
    "    \n",
    "    delayed_del = lab_pipeline.fit_transform(del_del.delayed_del.map({True:1, False:0}))\n",
    "    delayed_del = pd.DataFrame(delayed_del)\n",
    "    delayed_del.rename(columns = {0: 'delayed_del'}, inplace = True)\n",
    "\n",
    "    t_data = pd.concat([t_objects, t_num_log\n",
    "                        , ti, tc, tv, tm, tb\n",
    "                        , tml, tt], axis=1)\n",
    "    \n",
    "    print(\"X shape: \", t_data.shape, \"\\ny shape:\", delayed_del.shape)\n",
    "    \n",
    "    return t_data, delayed_del\n",
    "    \n",
    "    \n",
    "# classifier: split to train and test datasets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_set(X, y, ts, use_smote=False):\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=ts,\n",
    "                                                        random_state=103)\n",
    "    smote = SMOTE(ratio = 1.0, random_state=103)    \n",
    "    \n",
    "    if use_smote:         \n",
    "        X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    y_train = pd.DataFrame(y_train, columns=y.columns)\n",
    "    \n",
    "    print(\"Shape of X_train: {} X_val: {} y_train: {} y_val: {}\".format(X_train.shape,\n",
    "                                                                        X_test.shape,\n",
    "                                                                        y_train.shape,\n",
    "                                                                        y_test.shape))  \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# regression: split dataset\n",
    "def split_set_reg(X, true_pred, datetime, delayed_del):\n",
    "\n",
    "    # split for training\n",
    "    X_train_total = X.loc[delayed_del[delayed_del==1].dropna().index.tolist(),:]\n",
    "    X_train = X_train_total.drop(true_pred.index.tolist(), axis=0)\n",
    "\n",
    "    y_train_total = datetime.loc[delayed_del[delayed_del==1].dropna().index.tolist(),['delay_t']]\n",
    "    y_ttemp = y_train_total.drop(true_pred.index.tolist(), axis=0)\n",
    "    y_train = y_ttemp.delay_t.dt.days\n",
    "\n",
    "    # split for testing\n",
    "    X_test = X.loc[true_pred.index.tolist(),:]\n",
    "    y_test = datetime.loc[true_pred.index.tolist(),['delay_t']]['delay_t'].dt.days\n",
    "    \n",
    "    print(\"Shape of X_train: {} X_val: {} y_train: {} y_val: {}\".format(X_train.shape,\n",
    "                                                                        X_test.shape,\n",
    "                                                                        y_train.shape,\n",
    "                                                                        y_test.shape))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# select classifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, r2_score, mean_squared_error\n",
    "\n",
    "def select_classifier(X_train, X_test, y_train, y_test, clf):\n",
    "\n",
    "    ml = Pipeline([('estimator', clf)])\n",
    "\n",
    "    y_train = preprocessing.LabelEncoder().fit_transform(y_train.values.ravel())\n",
    "    y_test = preprocessing.LabelEncoder().fit_transform(y_test.values.ravel())\n",
    "    \n",
    "    ml.fit(X_train, y_train) # fit\n",
    "    pred = ml.predict(X_test) # predict\n",
    "    \n",
    "    return (f1_score(y_test, pred)) # return f1 score\n",
    "\n",
    "\n",
    "# collect true positivis from clf\n",
    "def collect_tr_pred(sel_clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    sel_clf.fit(X_train, y_train) # fit\n",
    "    y_pred = sel_clf.predict(X_test) # predict\n",
    "    \n",
    "    pred_df = y_test.copy() \n",
    "    pred_df['prediction']= y_pred\n",
    "\n",
    "    true_pred_df = pred_df[(pred_df.delayed_del==1) & (pred_df.delayed_del==pred_df.prediction)]\n",
    "    print(\"True positives:\\n\", true_pred_df.sum())\n",
    "    return true_pred_df\n",
    "\n",
    "\n",
    "# select regressor\n",
    "def select_regressor(X_train, X_test, y_train, y_test, reg):\n",
    "\n",
    "    ml = Pipeline([('estimator', reg)]) \n",
    "    \n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    ml.fit(X_train, y_train) # fit\n",
    "    pred = ml.predict(X_test) # predict\n",
    "    \n",
    "    r_score = (r2_score(y_test, pred), np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    return r_score # return r2, rmse\n",
    "\n",
    "\n",
    "# automate classification and regression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def classify_regress(X, y, datetime, clf, reg, test_size=0.2, use_smote=False):\n",
    "    \n",
    "    # Classification\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = split_set(X, y, test_size, use_smote=True)\n",
    "    clf_fit = clf.fit(X_train_c, y_train_c)\n",
    "    \n",
    "    # feature importance\n",
    "    try:\n",
    "        clf_importance = visualize_importance(clf_fit, X_train_c, 30)\n",
    "    except AttributeError:\n",
    "        clf_importance = pd.DataFrame([[]])\n",
    "        print(\"\\nCan't visualize feature importance for:\", clf)\n",
    "        \n",
    "    # classification report, conf matrix  \n",
    "    clf_report, conf_mtrx=[rm(y_test_c, clf_fit.predict(X_test_c)) for rm in [classification_report,\n",
    "                                                                                  confusion_matrix]]\n",
    "    \n",
    "    # true predicted \n",
    "    predicted = y_test_c.copy()\n",
    "    predicted['prediction']= clf.predict(X_test_c)\n",
    "    true_pred = predicted[(predicted.delayed_del==1) & (predicted.delayed_del==predicted.prediction)]\n",
    "    \n",
    "    # Regression\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = split_set_reg(X, true_pred,\n",
    "                                                             datetime, y) \n",
    "    reg.fit(X_train_r,y_train_r)\n",
    "    \n",
    "    # reg scores\n",
    "    r2 = r2_score(y_test_r, reg.predict(X_test_r))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_r, reg.predict(X_test_r)))\n",
    "    \n",
    "    return predicted, true_pred, clf_importance, clf_report, conf_mtrx, r2, rmse  \n",
    "\n",
    "\n",
    "# plot feature importance\n",
    "def visualize_importance(model, df, xlim):\n",
    "    \n",
    "    features = df.columns\n",
    "    major_features = pd.DataFrame(model.feature_importances_, features)\n",
    "    major_features.reset_index(inplace=True)\n",
    "    \n",
    "    major_features.columns=['feature', 'importance']\n",
    "    major_features.set_index('feature').sort_values(\n",
    "                                        'importance', ascending=False)[:30].plot(\n",
    "                                                                        kind=\"barh\",\n",
    "                                                                        xlim=(0, xlim),\n",
    "                                                                        figsize=(10,7),\n",
    "                                                                        color='tab:blue')\n",
    "    \n",
    "    \n",
    "# classification report\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "def class_report(X_train, X_test, y_train, y_test, est):    \n",
    "    ml = Pipeline([('estimator', est)])\n",
    "    report = ClassificationReport(ml, classes=['on-time', 'delayed']\n",
    "                                                    , cmap='YlGnBu')\n",
    "    report.fit(X_train, y_train)\n",
    "    report.score(X_test, y_test)\n",
    "    return report.poof()\n",
    "\n",
    "\n",
    "# cross-validation score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "\n",
    "def cross_val_report(clf, X, y, report_name):\n",
    "    \n",
    "    y = y.values.ravel()\n",
    "    scores = cross_validate(clf, X, y, cv=5, scoring=('precision', 'recall', 'f1'))\n",
    "    \n",
    "    validation_scores = {'precision': {}, 'recall': {}, 'f1': {}}\n",
    "    \n",
    "    for keys, values in scores.items():\n",
    "        \n",
    "            if 'precision' in keys:\n",
    "                if 'train' in keys:\n",
    "                    validation_scores['precision']['on-time'] = values.mean()\n",
    "                elif 'test' in keys:\n",
    "                    validation_scores['precision']['delayed'] = values.mean()\n",
    "                    \n",
    "            elif 'recall' in keys:\n",
    "                if 'train' in keys:\n",
    "                    validation_scores['recall']['on-time'] = values.mean()\n",
    "                elif 'test' in keys:\n",
    "                    validation_scores['recall']['delayed'] = values.mean()\n",
    "                    \n",
    "            elif 'f1' in keys:\n",
    "                if 'train' in keys:\n",
    "                    validation_scores['f1']['on-time'] = values.mean()\n",
    "                elif 'test' in keys:\n",
    "                    validation_scores['f1']['delayed'] = values.mean()        \n",
    "\n",
    "    a, b = plt.subplots(1, 1, figsize=(6,5))\n",
    "    ax = plt.axes()\n",
    "    ax.set_title(report_name)\n",
    "    return sns.heatmap(pd.DataFrame.from_dict(validation_scores),\n",
    "                                                       ax = ax,\n",
    "                                                       annot=True,\n",
    "                                                       fmt='.3f',\n",
    "                                                       linewidths=.5,\n",
    "                                                       cmap=\"YlGnBu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
